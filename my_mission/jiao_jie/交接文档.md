### 交接文档

---

---

```
==== Hr 服务器 ====
ip: 192.168.1.112
user: administrator
passwrod: Milky123!@#
```

---



##### 非hr相关模块

- 独立站评分检测脚本(自动执行)

- 接口冗余文件清除脚本(手动执行)

- geo检测脚本(定时脚本)

  |脚本名字| 相关功能| 需要注意的点|
  | ------------------- | --------------- | ------------------------------------------------------------ |
  | `start_detect.py`   | 独立站评分检测  | 每周三提醒，两个功能检测，没有用定时器，采用死循环定期跑脚本(一天：86400秒)，程序会用到公用的mongo数据库注意数据库崩溃 |
  | `clear_info.py`     | hr邀约接口清理  | 可以循环启动，但也可以不用管这个，偶尔手动启动也可以         |
  | `geo_post_and_get.py` | geo用量检测脚本 | 定时采用自己写的定时方法，只能整点触发，其他的信息在代码里面已经注释写好了。 |

##### hr检测后台系统

- 文件路径——文件名

  - `ZhilianDet`   >>>   `DjHr`     (首先定位到这个目录去 会看到 `manage.py`)

- 启动程序

  - `python manage.py runserver 0.0.0.0:8000`

- 注意事项

  - 这个可以直接用win终端跑，不需要开启额外的额IDE，减少负担。
  - 这个一定要启动，因为和智联岗位信息的检测相关。

- `django`后台账号密码

  - 主账号: `yhzx`     密码: `yhzxroot`

- 功能细分

  > `api` 接口文件路径中` ~/api/~`
  >
  > > `admin.py` 配置`admin`后台的显示模板
  > >
  > > `models.py`  主要处理数据库相关业务
  > >
  > > > 调整数据库的操作有: `python manage.py makemigrations`
  > > >
  > > > 然后还要迁移: `python manage.py migrate`
  > >
  > > `urls.py`  配置子路由的地方,里面涉及的正则功能会在`views.py`里面处理
  > >
  > > `views.py` 主要处理路由请求内容并返回数据的地方
  > >
  > > > 因为当初只有三个公司账号数据,所以只做了三个公司的数据处理,很多地方不建议修改，要不然爬虫程序那边修改的地方也挺多的。
  >
  > `DjHr` 主要的配置文件在这里面 
  >
  > > `settings.py` 配置数据库和注册应用的地方
  > >
  > > `urls.py` 配置主路由的
  >
  > `static` 静态文件
  >
  > `templates` 模板文件（因为是只用了 `admin` 后台，所以我只放了一个404页面）
  >
  > `manage.py`  项目的启动文件，启动方式如上





---

---

### HR数据相关的文档

---

*** 【注意以下内容大部分是需要 首次>>手动<<替换cookie】 **

#####  == 1 == 智联

######  账号所属分类表

| 文件夹名                  | 英文名   | 所属者 | 账号                | 端口 | 备注           |
| ------------------------- | -------- | ------ | ------------------- | ---- | -------------- |
| `zhilian_yhzx`            | shelly   | 张子珏 | `wwet67827992`      | 9010 | 银河在线主账号 |
| `zhilian_yhzx_hx`         | sarah    | 黄禧   | `anna20190818`      | 9081 |                |
| `zhilian_wbdz`            | ling     | 杨国玲 | `zc44288448qm`      | 9011 | 外宝电子主账号 |
| `zhilian_wbdz_hx`         | sarah    | 黄禧   | `nicole201909`      | 9013 |                |
| `zhilian_wbdz_lsy`        | laurinda | 廖淑颖 | `liaosy17620876419` | 9088 |                |
| `zhilian_wbdz-shelly2019` | shelly   | 张子珏 | `shelly2019`        | 9022 |                |
| `zhilian_ssm`             | linda    | 陈淼灵 | `52606463_uBOI`     | 9009 | 时时美主账号   |
| `zhilian_ssm_dq`          | nicole   | 邓琦   | `nicoledeng19`      | 9012 |                |

- 因为里面功能都是一样的，所以拿一个主账号来描述功能情况。
  - 启动检测功能:
    
    - 利用 `Pycharm` 启动程序 只需要启动  `文件夹名>>>crawl>>>timer.py `这个脚本就可以定时启动任务了
    
  - 定时脚本注意:
    - 主账号多了一个岗位检测功能,所以会多一个启动的脚本,其他账号有三个功能作为定时脚本长启动。
      - 主动投递检测(都有)
      - 下载的简历检测(都有)
      - 每日花销(都有)
      - **职位状态(主账号才有)**
    - 时间配置为定时器框架
    
  - 关于主账号特有检测详说
    - **检测脚本**
      - `spider >>> ZhiLian.py`  这个自动化脚本若是出了问题需要对应的HR人员登录（程序启动的窗口）来刷新本地的 `cookies.json` 文件,如果登录错了窗口需要删除`cookies.json`里面的 “cookies”:[中括号里面的内容，保留中括号],然后重新跑脚本就会到提醒让你登录的界面去，顺道会rt提醒到HR人员。
    - 检测时间设置
      - 这个无关紧要，设置在凌晨跑一次就好了
    - 可能出现的问题
      - 页面元素位置改变 >> 这个只能去修改对应的报错位置的地方
    
  - 关于账号共有的(默认启动的)功能
  
    - **上传接口里面的部分关键词**
  
      - account: 账号的英文名，同样在【配置文件】里面设置
  
      - company_dpt :  1-广州  2-义乌
      - resume_key: 简历关键词
      - get_type: 1-主动投递  2-主动下载
      - update_date: 简历的更新日期(是简历网站那边的)
      - resume_date: 简历的更新日期(我们上传到我们后台的更新日期)
      - account_from: 这个地方写这个账号的英文名,在 【配置文件】里面设置
  
    - 接口回传信息
  
      - 0： 上传成功，库里面没有，首次上传
      - 2： 简历已经存在，这是同一份简历在今天第二次上传
      - 3： 简历更新成功，库中有的简历，数据被更新
      - 6： 年龄大于40的不会上传到数据库
  
    - **主动投递(detail)**
  
      - 脚本: `spider >>> Zhaopin_detail_xxxx.py`  ：只需要注意detail这个关键字就好了，这就是主动投递的简历。
  
      - 功能: 检测每天的主动投递的信息
  
      - 特殊说明: 因为采用的是本地cookie，所以偶尔需要替换本地的cookie文件, 文件的位置为 `spider >>> cookies.py`  只需要复制一个浏览器的信息然后粘贴进来替换掉就好了，有时候还是可能会提醒找不到元素，要是cookie还能用，可能就是页面有验证框需要手动处理
  
      - 可手动处理: 要是有些时候数据没有获取到,但是时间过了，可以手动到 参数位置如下
  
        ```python
        params = {
                "_": f"{node}",
                "x-zp-page-request-id": f"{front[random.randint(0, max_len)]}-{node - random.randint(50, 1000)}-{random.randint(200000, 800000)}",
                "x-zp-client-id": "e5cc6ae7-13f9-4f11-ac17-f37439ae1de5",
                "S_CreateDate": f"{today_info},{today_info}",
                # "S_CreateDate": f"191103,191104",
                "S_ResumeState": f"{x}",     # 只查询待处理的信息
                "S_feedback": '""',
                "isNewList": "true",
                "page": i + 1,
                "pageSize": 20,       # 最多只能传100数据
                "searchSource": 1,
                "sort": "time",        # 目前顺序是最新 >> 最旧
            }
        ```
  
        日期设置和主动下载的简历位置是一样的， 就那个 `S_CreateDate`这个后面，默认就用动态参数，有些时候可以注释掉，然后修改下面那个注释掉的内容指定到某一段时间的内容来获取
  
      - 提醒： 因为智联的检测是根据`账号的点击频率`来检测或者抑制下一步的功能的，所以一般每条数据之间的获取间隔可能比较长，但是这么长的间隔还是可能会被检测到，所以可以根据日志里面的当前跑到了多少页来到指定位置手动从多少页开始跑数据。
  
    - **主动下载的简历(download)**
  
      - 脚本: `spider >>> Zhaopin_all_download_get.py` 这是每天下载的简历检测
      - 功能: 检测当天的下载的简历信息并上传
      - 特殊说明以及手动处理位置及提醒【 同 主动投递】
  
    - **每日花销检测**
  
      - 脚本: `spider >>> Zhilian_cost_much_detect_xxx.py`  这个是检测每日的账号花销详情的
      - 功能: 每天的检测
      - 这个接口里面的信息可以分开传，到目前为止 智联的接口改过一次，所以程序修改过一次，一般没有什么问题，这边主要就是保证cookie不过期可以检测很长时间。
  
  - 文件里面没有启动的脚本及功能
  
    - 原因: 因为现在主要是不下载简历，所以部分功能可以不用，主要启动上面的几个就好了，如果有必要，可以稍微启动下面的，不过不建议。
  
    - 脚本简略说明
  
      | 脚本名                       | 功能说明                                     | 备注                                                      |
      | ---------------------------- | -------------------------------------------- | --------------------------------------------------------- |
      | `ZhiLian_keywords_search.py` | 智联的关键字搜索简历功能                     | 很容易出现大量重复的，还是人为去处理的好                  |
      | `Zhilian_while_download.py`  | 通过系统里面的下载按钮下载上面脚本下载的简历 | 多个账号要是都搜不到很容易出现账号点击频率过高问题        |
      | `Zhilian_while_send.py`      | 邀约后在智联后台再去点击邀约的功能           | 不用这个，有个单独的脚本处理接口里面的信息(clear_info.py) |
  
    - 其中很多free开头的是没有涉及的rt提醒的，很多时候处理一些事可以用那些 当然也可以手动关闭rt
  
  - **配置文件**(这里面主要是`python_config.py`)
  
    - `python_config.py`  >>> (主要的信息我会加粗)
      - handler: 出了问题是谁处理(为了方便定位到是谁的账号好排查错误)
      - receiver: RT收信息(*不要添加陈总进去,哪怕他叫你添加你也别添加,我反正就这样*)
      - company_name: 公司信息，也是为了方便定位账号的
      - **account_main**: 关键信息，这个账号的ID
      - **account_from**: 账号所属者的英文名
      - staffName: 内部员工ID，这个参数是早期的时候定位到员工的，现在是个无用参数，可以随便写
      - DOWN_ACCOUTN: 为了确定什么公司---什么人的账号信息
      - CHROME_PORT: 启动本地端口的端口，和下面注释的那句搭配使用
        - 端口要确定一个账号一个端口，账号保存路径建议设置的比较容易区分，同样是一个账号一个专属的路径
    - `mysql_config.py`  >>> 配置数据库的配置文件
  
  - 日志文件
  
    - `utils` >>> 里面信息是按 **年月** 来分类的，方便排查问题
  
  - **定时器**(也是启动程序的地方)
  
    - `timer.py`   只需要启动这个就好了，就能启动默认设置好的功能
      - 这里面主要需要注意的是假如多了账号需要处理的事情，需要修改文件名，我的文件名不是每个都一样的，当初没有想到现在这么多账号，所以还是需要留意一下
  
###### 添加账号

  - 比如张三是美豆电子的 你就需要做以下事情
    - 复制一份
    - 修改文件名 `Zhilian_mddz_zs`
    - 清除里面的日志信息
    - 修改配置文件（`python_config.py` 里面）
      - handler
      - receiver
      - company_name
      - account_main
      - account_from (这里一定要问她的英文名，英文名都要小写开头)
      - **CHROME_PORT 这里建议选择一个没有用过的端口，然后改好后面的注释里面的内容，复制了到终端执行一下，就能开启一个新的窗口了，然后建议添加一个快捷按钮 （名字:这里写能让你清除知道这是什么平台的谁的账号的名字，地址随便写，然后可以执行一下`free_while_download.py `这个脚本就会调用本地的浏览器了，记得一定要把`cookies.json`里面的cookie信息删除，然后就会`卡到账号登录的界面`，然后这时候可以`让hr来登录`，然后登录信息就会被保存下来。只要进去了，看到日志里面出现--本地的cookie已经刷新了，就可以停掉这个脚本了，复制一份`cookie`到`cookies.py`里面去替换了就可以启动程序了，其他的就等报错的时候检查了，一般没有什么问题，所以rt一定要加上你自己）**

###### 一般的错误及解决方案

- 弹出账号cookie过期
  - 这个可以看看本地的那个浏览器的那个账号，刷新一下，要是还在那就有两种可能
    - 有验证码： 手动点开一份简历，弹出来处理掉就好了
    - 有职位下线提醒： 这个不知道怎么处理，不管它就好了
- 替换了cookie依旧不能获取元素信息
  - 需要检查当前脚本是否可用，避免页面元素修改，节点信息变更



---

---

##### == 2 == 前程无忧

###### 账号所属分类表

| 文件夹名            | 英文名 | 所属者 | 账号      | 密码           | 端口  | 公司     |
| ------------------- | ------ | ------ | --------- | -------------- | ----- | -------- |
| `Job51_yhzx_shelly` | shelly | 张子珏 | `yhzx151` | `yhzx2019`     | 23355 | 银河在线 |
| `Job51_wbdz_ling`   | ling   | 杨国玲 | `gzwb537` | `jewelry81087` | 25533 | 外宝电子 |
| `Job51_ssm_linda`   | linda  | 陈淼灵 | `ymrj483` | `yhzx10`       | 23333 | 时时美   |

###### 主要功能分类

- 因为功能整合了，所以是一个程序来处理所有任务

  - 主要的脚本位置

    - `Job51 >> detail_and_down.py`  : 只需要启动这个脚本就好了
    - `Job51 >> download_today.py`  ：每天看情况配置，这里面需要修改的就一个地方如下

    ```python
    def do_click_search(self):
        # today_tic = time.strftime('%Y-%m-%d', time.localtime(time.time()))
        today_tic = time.strftime('%Y-%m-%d', time.localtime(time.time() - 86400))
        # today_tic = time.strftime('%Y-%m-%d', time.localtime(time.time() - 86400 * 2))
        # today_tic = time.strftime('%Y-%m-%d', time.localtime(time.time() - 86400 * 3))
        time.sleep(random.uniform(0, 1))
    ```

    上面是决定你当天跑哪一天的数据，默认是保留第二个，处理昨天的数据，要是周末不在的话，但是周六hr又下载了数据，所以下周一跑的时候需要开启第三条数据

  - 特别注意

    - 前程的机制是：账号的cookie每天过期，所以第二天你的账号就会被下线，而且hr也会用这个平台，前程只支持单处登录，所以：：**每天早上手动跑程序**，前程的HR端和用户端是不一样的，所以目前我们只能通过自动化爬取数据，而且他们检测自动化工具很严格，**只能启动本地浏览器调用**.

###### 常见错误问题

- 第二天手动登录需要验证

  - 这个需要找对应的hr配置，你请求验证码，她们发给你

- 部分数据获取失败

  - 因为有的简历的模板和大多数模板不一样，可能在这一封简历就会报错，如果需要获取后面的简历，就要把它跳过，具体跳过的代码位置是

    ```python
    if tic_num == 0:
        return False
    else:
        for i in range(1, tic_num + 1):
        # for i in range(1, 51):
        #     if i == 37:
            self.driver.switch_to.window(self.driver.window_handles[0])
            time.sleep(1)
    ```

    这里可能需要手动数一数哪个出问题，就把它跳过

- 不能获取任何数据

  - 可能是页面出现了广告,小概率事件，可能需要修改容错
  - 页面元素变更，可能存在的情况，需要看报错位置进行重新定位处理



---

---

##### == 3 == 58同城

###### 账号分类所属表



